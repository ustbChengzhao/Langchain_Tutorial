{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c3bbcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c16a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 载入Chat Models\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f08f37",
   "metadata": {},
   "source": [
    "## 1. Messages\n",
    "Messages包括：\n",
    "+ **System Message**\n",
    "+ **AIMessage**\n",
    "+ **HumanMessage**\n",
    "+ FunctionMessage\n",
    "+ ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca00a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatModels接收List[BaseMessage]作为输入\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the purpose of model regularization?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa68af63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The purpose of model regularization in machine learning is to prevent overfitting and improve the generalization ability of the model. Overfitting occurs when a model learns the training data too well, including noise and irrelevant patterns, which can lead to poor performance on new, unseen data. Regularization techniques add a penalty term to the model's loss function to discourage overly complex models and encourage simpler, more generalizable models. This helps to strike a balance between fitting the training data well and being able to make accurate predictions on new data.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964132d3",
   "metadata": {},
   "source": [
    "## 2. 直接调用(Legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9911eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The purpose of model regularization is to prevent overfitting in machine learning models. Overfitting occurs when a model learns the training data too well, including the noise and outliers, and performs poorly on new, unseen data. Regularization techniques help to simplify the model by adding a penalty term to the loss function, which discourages the model from becoming too complex and helps improve its generalization performance on unseen data. Regularization techniques such as L1 (Lasso) and L2 (Ridge) regularization are commonly used to achieve this goal.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f73aa7",
   "metadata": {},
   "source": [
    "## 3. generate\n",
    "一次处理批量的对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cdfdcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=\"J'adore la programmation.\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"J'adore la programmation.\"))], [ChatGeneration(text=\"J'adore l'intelligence artificielle.\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"J'adore l'intelligence artificielle.\"))]], llm_output={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 53, 'total_tokens': 73}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_69829325d0'}, run=[RunInfo(run_id=UUID('c05e85bd-3120-4174-892f-dcc2a4529df0')), RunInfo(run_id=UUID('cee270a1-82e7-4cbf-a7cf-86a57fbdcc27'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that translates English to French.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"I love programming.\"),\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that translates English to French.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"I love artificial intelligence.\"),\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6d36c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 20,\n",
       "  'prompt_tokens': 53,\n",
       "  'total_tokens': 73},\n",
       " 'model_name': 'gpt-3.5-turbo',\n",
       " 'system_fingerprint': 'fp_69829325d0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a04220",
   "metadata": {},
   "source": [
    "## 4. Caching\n",
    "+ 如果多次相同的请求，可以减小API调用\n",
    "+ 节约资金\n",
    "+ 加快速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31bd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "505c421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.9 ms, sys: 38.3 ms, total: 84.2 ms\n",
      "Wall time: 1.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# 第一次不在缓存中，会花费很长时间\n",
    "llm.predict(\"Tell me a joke.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402b498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 ms, sys: 4.16 ms, total: 27.1 ms\n",
      "Wall time: 1.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 第二次会快很多\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573ba25",
   "metadata": {},
   "source": [
    "## 5. Function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5e2d7",
   "metadata": {},
   "source": [
    "#### 1. 定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cedf2268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"multiply\",\n",
      "    \"description\": \"Multiply two integers together.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"First integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"Second integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiply two integers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(multiply), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5fc4a3",
   "metadata": {},
   "source": [
    "#### 2. 把函数传给模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b2af40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nDe2IQbafih8Cgwar6FArfjq', 'function': {'arguments': '{\"a\":5,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm.invoke(\"what's 5 times three\", tools=[convert_to_openai_tool(multiply)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3775258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HSF0d6zlXaZEAxghsS6zRm9x', 'function': {'arguments': '{\"a\":5,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每次都调用这个工具\n",
    "llm_with_tool = llm.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "llm_with_tool.invoke(\"what's 5 times 3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290b2a0",
   "metadata": {},
   "source": [
    "## 6. Tracking token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94beb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d725c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 28\n",
      "\tPrompt Tokens: 12\n",
      "\tCompletion Tokens: 16\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $4.9999999999999996e-05\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a joke.\")\n",
    "    print(cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
