{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e81917e",
   "metadata": {},
   "source": [
    "## 1. Vector store-backed retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8c8af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your API KEY:········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Your API KEY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97926343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./example data/hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64adefe1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1307, which is longer than the specified 1000\n",
      "Created a chunk of size 4126, which is longer than the specified 1000\n",
      "Created a chunk of size 2446, which is longer than the specified 1000\n",
      "Created a chunk of size 7752, which is longer than the specified 1000\n",
      "Created a chunk of size 4735, which is longer than the specified 1000\n",
      "Created a chunk of size 2413, which is longer than the specified 1000\n",
      "Created a chunk of size 4118, which is longer than the specified 1000\n",
      "Created a chunk of size 1808, which is longer than the specified 1000\n",
      "Created a chunk of size 2816, which is longer than the specified 1000\n",
      "Created a chunk of size 5153, which is longer than the specified 1000\n",
      "Created a chunk of size 1735, which is longer than the specified 1000\n",
      "Created a chunk of size 2029, which is longer than the specified 1000\n",
      "Created a chunk of size 3485, which is longer than the specified 1000\n",
      "Created a chunk of size 2235, which is longer than the specified 1000\n",
      "Created a chunk of size 1987, which is longer than the specified 1000\n",
      "Created a chunk of size 2632, which is longer than the specified 1000\n",
      "Created a chunk of size 2128, which is longer than the specified 1000\n",
      "Created a chunk of size 2365, which is longer than the specified 1000\n",
      "Created a chunk of size 6993, which is longer than the specified 1000\n",
      "Created a chunk of size 1116, which is longer than the specified 1000\n",
      "Created a chunk of size 1560, which is longer than the specified 1000\n",
      "Created a chunk of size 1424, which is longer than the specified 1000\n",
      "Created a chunk of size 4146, which is longer than the specified 1000\n",
      "Created a chunk of size 2788, which is longer than the specified 1000\n",
      "Created a chunk of size 5125, which is longer than the specified 1000\n",
      "Created a chunk of size 1315, which is longer than the specified 1000\n",
      "Created a chunk of size 2468, which is longer than the specified 1000\n",
      "Created a chunk of size 1792, which is longer than the specified 1000\n",
      "Created a chunk of size 1898, which is longer than the specified 1000\n",
      "Created a chunk of size 1337, which is longer than the specified 1000\n",
      "Created a chunk of size 2050, which is longer than the specified 1000\n",
      "Created a chunk of size 1414, which is longer than the specified 1000\n",
      "Created a chunk of size 2022, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1206, which is longer than the specified 1000\n",
      "Created a chunk of size 1304, which is longer than the specified 1000\n",
      "Created a chunk of size 2301, which is longer than the specified 1000\n",
      "Created a chunk of size 1220, which is longer than the specified 1000\n",
      "Created a chunk of size 4706, which is longer than the specified 1000\n",
      "Created a chunk of size 5622, which is longer than the specified 1000\n",
      "Created a chunk of size 1545, which is longer than the specified 1000\n",
      "Created a chunk of size 1216, which is longer than the specified 1000\n",
      "Created a chunk of size 2588, which is longer than the specified 1000\n",
      "Created a chunk of size 2774, which is longer than the specified 1000\n",
      "Created a chunk of size 1064, which is longer than the specified 1000\n",
      "Created a chunk of size 1647, which is longer than the specified 1000\n",
      "Created a chunk of size 2116, which is longer than the specified 1000\n",
      "Created a chunk of size 1022, which is longer than the specified 1000\n",
      "Created a chunk of size 1261, which is longer than the specified 1000\n",
      "Created a chunk of size 1722, which is longer than the specified 1000\n",
      "Created a chunk of size 6213, which is longer than the specified 1000\n",
      "Created a chunk of size 1653, which is longer than the specified 1000\n",
      "Created a chunk of size 2448, which is longer than the specified 1000\n",
      "Created a chunk of size 1546, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 4263, which is longer than the specified 1000\n",
      "Created a chunk of size 4484, which is longer than the specified 1000\n",
      "Created a chunk of size 3786, which is longer than the specified 1000\n",
      "Created a chunk of size 5191, which is longer than the specified 1000\n",
      "Created a chunk of size 1469, which is longer than the specified 1000\n",
      "Created a chunk of size 7335, which is longer than the specified 1000\n",
      "Created a chunk of size 2169, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760dc9e",
   "metadata": {},
   "source": [
    "#### 默认使用相似性搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cda4a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham. To be, or not to be- that is the question:\n",
      "    Whether 'tis nobler in the mind to suffer\n",
      "    The slings and arrows of outrageous fortune\n",
      "    Or to take arms against a sea of troubles,\n",
      "    And by opposing end them. To die- to sleep-\n",
      "    No more; and by a sleep to say we end\n",
      "    The heartache, and the thousand natural shocks\n",
      "    That flesh is heir to. 'Tis a consummation  \n",
      "    Devoutly to be wish'd. To die- to sleep.\n",
      "    To sleep- perchance to dream: ay, there's the rub!\n",
      "    For in that sleep of death what dreams may come\n",
      "    When we have shuffled off this mortal coil,\n",
      "    Must give us pause. There's the respect\n",
      "    That makes calamity of so long life.\n",
      "    For who would bear the whips and scorns of time,\n",
      "    Th' oppressor's wrong, the proud man's contumely,\n",
      "    The pangs of despis'd love, the law's delay,\n",
      "    The insolence of office, and the spurns\n",
      "    That patient merit of th' unworthy takes,\n",
      "    When he himself might his quietus make\n",
      "    With a bare bodkin? Who would these fardels bear,\n",
      "    To grunt and sweat under a weary life,\n",
      "    But that the dread of something after death-\n",
      "    The undiscover'd country, from whose bourn\n",
      "    No traveller returns- puzzles the will,\n",
      "    And makes us rather bear those ills we have\n",
      "    Than fly to others that we know not of?\n",
      "    Thus conscience does make cowards of us all,  \n",
      "    And thus the native hue of resolution\n",
      "    Is sicklied o'er with the pale cast of thought,\n",
      "    And enterprises of great pith and moment\n",
      "    With this regard their currents turn awry\n",
      "    And lose the name of action.- Soft you now!\n",
      "    The fair Ophelia!- Nymph, in thy orisons\n",
      "    Be all my sins rememb'red.\n",
      "  Oph. Good my lord,\n",
      "    How does your honour for this many a day?\n",
      "  Ham. I humbly thank you; well, well, well.\n",
      "  Oph. My lord, I have remembrances of yours\n",
      "    That I have longed long to re-deliver.\n",
      "    I pray you, now receive them.\n",
      "  Ham. No, not I!\n",
      "    I never gave you aught.\n",
      "  Oph. My honour'd lord, you know right well you did,\n",
      "    And with them words of so sweet breath compos'd\n",
      "    As made the things more rich. Their perfume lost,\n",
      "    Take these again; for to the noble mind\n",
      "    Rich gifts wax poor when givers prove unkind.  \n",
      "    There, my lord.\n",
      "  Ham. Ha, ha! Are you honest?\n",
      "  Oph. My lord?\n",
      "  Ham. Are you fair?\n",
      "  Oph. What means your lordship?\n",
      "  Ham. That if you be honest and fair, your honesty should admit no\n",
      "    discourse to your beauty.\n",
      "  Oph. Could beauty, my lord, have better commerce than with honesty?\n",
      "  Ham. Ay, truly; for the power of beauty will sooner transform\n",
      "    honesty from what it is to a bawd than the force of honesty can\n",
      "    translate beauty into his likeness. This was sometime a paradox,\n",
      "    but now the time gives it proof. I did love you once.\n",
      "  Oph. Indeed, my lord, you made me believe so.\n",
      "  Ham. You should not have believ'd me; for virtue cannot so\n",
      "    inoculate our old stock but we shall relish of it. I loved you\n",
      "    not.\n",
      "  Oph. I was the more deceived.\n",
      "  Ham. Get thee to a nunnery! Why wouldst thou be a breeder of\n",
      "    sinners? I am myself indifferent honest, but yet I could accuse\n",
      "    me of such things that it were better my mother had not borne me.  \n",
      "    I am very proud, revengeful, ambitious; with more offences at my\n",
      "    beck than I have thoughts to put them in, imagination to give\n",
      "    them shape, or time to act them in. What should such fellows as I\n",
      "    do, crawling between earth and heaven? We are arrant knaves all;\n",
      "    believe none of us. Go thy ways to a nunnery. Where's your\n",
      "    father?\n",
      "  Oph. At home, my lord.\n",
      "  Ham. Let the doors be shut upon him, that he may play the fool\n",
      "    nowhere but in's own house. Farewell.\n",
      "  Oph. O, help him, you sweet heavens!\n",
      "  Ham. If thou dost marry, I'll give thee this plague for thy dowry:\n",
      "    be thou as chaste as ice, as pure as snow, thou shalt not escape\n",
      "    calumny. Get thee to a nunnery. Go, farewell. Or if thou wilt\n",
      "    needs marry, marry a fool; for wise men know well enough what\n",
      "    monsters you make of them. To a nunnery, go; and quickly too.\n",
      "    Farewell.\n",
      "  Oph. O heavenly powers, restore him!\n",
      "  Ham. I have heard of your paintings too, well enough. God hath\n",
      "    given you one face, and you make yourselves another. You jig, you\n",
      "    amble, and you lisp; you nickname God's creatures and make your  \n",
      "    wantonness your ignorance. Go to, I'll no more on't! it hath made\n",
      "    me mad. I say, we will have no moe marriages. Those that are\n",
      "    married already- all but one- shall live; the rest shall keep as\n",
      "    they are. To a nunnery, go.                            Exit.\n",
      "  Oph. O, what a noble mind is here o'erthrown!\n",
      "    The courtier's, scholar's, soldier's, eye, tongue, sword,\n",
      "    Th' expectancy and rose of the fair state,\n",
      "    The glass of fashion and the mould of form,\n",
      "    Th' observ'd of all observers- quite, quite down!\n",
      "    And I, of ladies most deject and wretched,\n",
      "    That suck'd the honey of his music vows,\n",
      "    Now see that noble and most sovereign reason,\n",
      "    Like sweet bells jangled, out of tune and harsh;\n",
      "    That unmatch'd form and feature of blown youth\n",
      "    Blasted with ecstasy. O, woe is me\n",
      "    T' have seen what I have seen, see what I see!\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents('What profound philosophical issues does Hamlet explore in his \"To be, or not to be\" soliloquy in the play?')\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c3b65",
   "metadata": {},
   "source": [
    "#### 指定搜索类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2a24dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\")\n",
    "docs = retriever.get_relevant_documents('What profound philosophical issues does Hamlet explore in his \"To be, or not to be\" soliloquy in the play?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9f874",
   "metadata": {},
   "source": [
    "#### 设定相似度阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85451f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                            search_kwargs={\"score_threshold\": 0.5})\n",
    "docs = retriever.get_relevant_documents('What profound philosophical issues does Hamlet explore in his \"To be, or not to be\" soliloquy in the play?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0da2da",
   "metadata": {},
   "source": [
    "#### top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbfa593b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "docs = retriever.get_relevant_documents(\"what did he say about ketanji brown jackson\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf8f39",
   "metadata": {},
   "source": [
    "## 2. MultiQueryRetriever\n",
    "使用LLM从不同的角度为用户输入的查询生成多个查询，获得更丰富的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c985a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a sample vectorDB\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load blog post\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(data)\n",
    "\n",
    "# VectorDB\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152d4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4249c1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]\n"
     ]
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "print(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd974f",
   "metadata": {},
   "source": [
    "## 3. Contextual compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9363ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01760911",
   "metadata": {},
   "source": [
    "#### 不压缩直接输出对应文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c41e1f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
      "\n",
      "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "And for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \n",
      "\n",
      "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
      "\n",
      "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \n",
      "\n",
      "And soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \n",
      "\n",
      "So tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \n",
      "\n",
      "First, beat the opioid epidemic.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \n",
      "\n",
      "And as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \n",
      "\n",
      "That ends on my watch. \n",
      "\n",
      "Medicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \n",
      "\n",
      "We’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \n",
      "\n",
      "Let’s pass the Paycheck Fairness Act and paid leave.  \n",
      "\n",
      "Raise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \n",
      "\n",
      "Let’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "documents = TextLoader(\"./example data/state_of_the_union.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    "\n",
    "docs = retriever.get_relevant_documents(\n",
    "    \"What did the president say about Ketanji Brown Jackson\"\n",
    ")\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc085b2",
   "metadata": {},
   "source": [
    "#### 文本压缩：LLMChainExtractor\n",
    "从最初返回的Documents中检索，仅返回与query最相近的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c4a0d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    \"What did the president say about Ketanji Jackson Brown\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d134c",
   "metadata": {},
   "source": [
    "#### 过滤器Filter：LLMChainFilter\n",
    "利用LLMChain，从最初返回的Documents中检索，过滤掉相关度较低的，返回相关度高的，对Document不做操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00abf055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/apple/anaconda3/envs/pytorch/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "\n",
    "_filter = LLMChainFilter.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=_filter, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    \"What did the president say about Ketanji Jackson Brown\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1e4f4",
   "metadata": {},
   "source": [
    "#### 过滤器Filter：EmbeddingsFilter\n",
    "对最初的Documents和query根据Embedding过滤掉相关度较低的，返回相关度高的，对Document不做操作，用于简单场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c4d497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
      "\n",
      "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    \"What did the president say about Ketanji Jackson Brown\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033b77e",
   "metadata": {},
   "source": [
    "#### 串联压缩器和文本转换器\n",
    "对最初返回的所有Documents都进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05c280bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\". \")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, redundant_filter, relevant_filter]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007970e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
      "\n",
      "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    \"What did the president say about Ketanji Jackson Brown\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242dfda",
   "metadata": {},
   "source": [
    "## 4. Ensemble Retriever\n",
    "+ 将Retriever列表作为输入，把他们的结果集成到一起\n",
    "+ 把稀疏检索器和密集检索器结合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c21da335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8081cfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I like oranges', metadata={'source': 1}),\n",
       " Document(page_content='You like oranges', metadata={'source': 2}),\n",
       " Document(page_content='Apples and oranges are fruits', metadata={'source': 1}),\n",
       " Document(page_content='You like apples', metadata={'source': 2})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list_1 = [\n",
    "    \"I like apples\",\n",
    "    \"I like oranges\",\n",
    "    \"Apples and oranges are fruits\",\n",
    "]\n",
    "\n",
    "doc_list_2 = [\n",
    "    \"You like apples\",\n",
    "    \"You like oranges\",\n",
    "]\n",
    "\n",
    "# initialize the bm25 retriever \n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n",
    ")\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "# initialize the faiss retriever\n",
    "embedding = OpenAIEmbeddings()\n",
    "faiss_vectorstore = FAISS.from_texts(\n",
    "    doc_list_2, embedding, metadatas=[{\"source\": 2}] * len(doc_list_2)\n",
    ")\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "docs = ensemble_retriever.invoke(\"oranges\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf3411",
   "metadata": {},
   "source": [
    "## 5. Long-Context Reorder\n",
    "当文档过长时，相关信息位于文本的开始或结束时效果最好，位于中间时效果会受到影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b59cd552",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The Celtics are my favourite team.'),\n",
       " Document(page_content='This is a document about the Boston Celtics'),\n",
       " Document(page_content='The Boston Celtics won the game by 20 points'),\n",
       " Document(page_content='L. Kornet is one of the best Celtics players.'),\n",
       " Document(page_content='Basquetball is a great sport.'),\n",
       " Document(page_content='Larry Bird was an iconic NBA player.'),\n",
       " Document(page_content='would like me to clarify?\"', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='This is just a random text.'),\n",
       " Document(page_content='... (Repeated many times)', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='I simply love going to the movies')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_transformers import (\n",
    "    LongContextReorder,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "texts = [\n",
    "    \"Basquetball is a great sport.\",\n",
    "    \"Fly me to the moon is one of my favourite songs.\",\n",
    "    \"The Celtics are my favourite team.\",\n",
    "    \"This is a document about the Boston Celtics\",\n",
    "    \"I simply love going to the movies\",\n",
    "    \"The Boston Celtics won the game by 20 points\",\n",
    "    \"This is just a random text.\",\n",
    "    \"Elden Ring is one of the best games in the last 15 years.\",\n",
    "    \"L. Kornet is one of the best Celtics players.\",\n",
    "    \"Larry Bird was an iconic NBA player.\",\n",
    "]\n",
    "\n",
    "# Create a retriever\n",
    "retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "\n",
    "query = \"What can you tell me about the Celtics?\"\n",
    "\n",
    "# Get relevant documents ordered by relevance score\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c279c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This is a document about the Boston Celtics'),\n",
       " Document(page_content='L. Kornet is one of the best Celtics players.'),\n",
       " Document(page_content='Larry Bird was an iconic NBA player.'),\n",
       " Document(page_content='This is just a random text.'),\n",
       " Document(page_content='I simply love going to the movies'),\n",
       " Document(page_content='... (Repeated many times)', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='would like me to clarify?\"', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Basquetball is a great sport.'),\n",
       " Document(page_content='The Boston Celtics won the game by 20 points'),\n",
       " Document(page_content='The Celtics are my favourite team.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder the documents:\n",
    "# Less relevant document will be at the middle of the list and more\n",
    "# relevant elements at beginning / end.\n",
    "reordering = LongContextReorder()\n",
    "reordered_docs = reordering.transform_documents(docs)\n",
    "\n",
    "# Confirm that the 4 relevant documents are at beginning and end.\n",
    "reordered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c0245b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. MultiVector Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91eed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
